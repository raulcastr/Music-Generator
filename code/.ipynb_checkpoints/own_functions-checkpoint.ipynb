{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import music21\n",
    "import glob\n",
    "import pickle\n",
    "from keras import layers\n",
    "\n",
    "import keras.backend as K \n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi_parsed(seq_len = 32,mode = \"read\"):\n",
    "    notes = []\n",
    "    durations = []\n",
    "    \n",
    "    if mode==\"read\":\n",
    "        path_list = glob.glob(os.path.join(\"../data/training_songs/\", \"*.mid\"))\n",
    "        print(len(path_list), 'files in total')\n",
    "\n",
    "        for i, file in enumerate(path_list):\n",
    "            print(i+1, \"Parsing %s\" % file)\n",
    "            original_score = music21.converter.parse(file).chordify()\n",
    "\n",
    "            for interval in range(1):\n",
    "\n",
    "                score = original_score.transpose(interval)\n",
    "\n",
    "                notes.extend(['START'] * seq_len)\n",
    "                durations.extend([0]* seq_len)\n",
    "\n",
    "                for element in score.flat:\n",
    "\n",
    "                    if isinstance(element, music21.note.Note):\n",
    "                        if element.isRest:\n",
    "                            notes.append(str(element.name))\n",
    "                            durations.append(element.duration.quarterLength)\n",
    "                        else:\n",
    "                            notes.append(str(element.nameWithOctave))\n",
    "                            durations.append(element.duration.quarterLength)\n",
    "\n",
    "                    if isinstance(element, music21.chord.Chord):\n",
    "                        notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "\n",
    "        \n",
    "        pickle.dump(notes, open(\"../data/stored_data/parsed_data/notes\", \"wb\"))\n",
    "        pickle.dump(durations, open(\"../data/stored_data/parsed_data/durations\", \"wb\"))\n",
    "        \n",
    "    else:\n",
    "        notes = pickle.load(open(\"../data/stored_data/parsed_data/notes\", \"rb\"))\n",
    "        durations = pickle.load(open(\"../data/stored_data/parsed_data/durations\", \"rb\"))\n",
    "        \n",
    "    return notes , durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(n_notes, n_durations, embed_size = 100, rnn_units = 256):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    # There are two inputs to the network: the sequence of previous note names and duration values. \n",
    "    notes_in = layers.Input(shape = (None,))\n",
    "    durations_in = layers.Input(shape = (None,))\n",
    "    \n",
    "    # The Embedding layers convert the integer values of the note names and durations into vectors.\n",
    "    x1 = layers.Embedding(n_notes, embed_size)(notes_in)\n",
    "    x2 = layers.Embedding(n_durations, embed_size)(durations_in) \n",
    "    \n",
    "    # The vectors are concatenated to form one long vector that will be used as input into the recurrent layers.\n",
    "    x = layers.Concatenate()([x1,x2])\n",
    "    \n",
    "    # Two stacked LSTM layers are used as the recurrent part of the network. Notice how we set return_sequences to True to make \n",
    "    # each layer pass the full sequence of hidden states to the next layer, rather than just the final hidden state.\n",
    "    x = layers.LSTM(rnn_units, return_sequences=True)(x)\n",
    "    x = layers.LSTM(rnn_units, return_sequences=True)(x)\n",
    "\n",
    "    # The alignment function is just a Dense layer with one output unit and tanh activation. We can use a Reshape layer to \n",
    "    # squash the output to a single vector, of length equal to the length of the input sequence (seq_length).\n",
    "    e = layers.Dense(1, activation='tanh')(x)\n",
    "    e = layers.Reshape([-1])(e)\n",
    "    \n",
    "    # The weights are calculated through applying a softmax activation to the alignment values.\n",
    "    alpha = layers.Activation('softmax')(e)\n",
    "    \n",
    "    # To get the weighted sum of the hidden states, we need to use a RepeatVector layer to copy the weights rnn_units times\n",
    "    # to form a matrix of shape [rnn_units, seq_length], then transpose this matrix using a Permute layer to get a matrix of \n",
    "    # shape [seq_length, rnn_units]. We can then multiply this matrix pointwise with the hidden states from the final LSTM layer,\n",
    "    # which also has shape [seq_length, rnn_units]. Finally, we use a Lambda layer to perform the summation along the seq_length \n",
    "    # axis, to give the context vector of length rnn_units.\n",
    "    alpha_repeated = layers.Permute([2, 1])(layers.RepeatVector(rnn_units)(alpha))\n",
    "    c = layers.Multiply()([x, alpha_repeated])\n",
    "    c = layers.Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c)\n",
    "    \n",
    "    # The network has a double-headed output, one for the next note name and one for the next note length.\n",
    "    notes_out = layers.Dense(n_notes, activation = 'softmax', name = 'pitch')(c)\n",
    "    durations_out = layers.Dense(n_durations, activation = 'softmax', name = 'duration')(c)\n",
    "   \n",
    "    # The final model accepts the previous note names and note durations as input and outputs a distribution\n",
    "    # for the next note name and next note duration.\n",
    "    model = Model([notes_in, durations_in], [notes_out, durations_out])\n",
    "   \n",
    "    # The model is compiled using categorical_crossentropy for both the note name and note duration output heads, as this is a\n",
    "    # multiclass classification problem.\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], optimizer=RMSprop(lr = 0.001))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, durations, lookups, distincts, seq_len =32):\n",
    "    # Prepare the sequences used to train the Neural Network \n",
    "\n",
    "    note_to_int, int_to_note, duration_to_int, int_to_duration = lookups\n",
    "    note_names, n_notes, duration_names, n_durations = distincts\n",
    "\n",
    "    notes_network_input = []\n",
    "    notes_network_output = []\n",
    "    durations_network_input = []\n",
    "    durations_network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(len(notes) - seq_len):\n",
    "        notes_sequence_in = notes[i:i + seq_len]\n",
    "        notes_sequence_out = notes[i + seq_len]\n",
    "        notes_network_input.append([note_to_int[char] for char in notes_sequence_in])\n",
    "        notes_network_output.append(note_to_int[notes_sequence_out])\n",
    "\n",
    "        durations_sequence_in = durations[i:i + seq_len]\n",
    "        durations_sequence_out = durations[i + seq_len]\n",
    "        durations_network_input.append([duration_to_int[char] for char in durations_sequence_in])\n",
    "        durations_network_output.append(duration_to_int[durations_sequence_out])\n",
    "\n",
    "    n_patterns = len(notes_network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    notes_network_input = np.reshape(notes_network_input, (n_patterns, seq_len))\n",
    "    durations_network_input = np.reshape(durations_network_input, (n_patterns, seq_len))\n",
    "    network_input = [notes_network_input, durations_network_input]\n",
    "\n",
    "    notes_network_output = np_utils.to_categorical(notes_network_output, num_classes=n_notes)\n",
    "    durations_network_output = np_utils.to_categorical(durations_network_output, num_classes=n_durations)\n",
    "    network_output = [notes_network_output, durations_network_output]\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temp(preds, temperature):\n",
    "# We sample from both of these distributions, using a temperature parameter to control how much variation we would like \n",
    "# in the sampling process.\n",
    "    if temperature == 0:\n",
    "        return np.argmax(preds)\n",
    "    else:\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        return np.random.choice(len(preds), p=preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
